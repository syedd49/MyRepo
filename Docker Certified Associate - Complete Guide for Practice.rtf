{\rtf1\ansi\ansicpg1252\deff0\nouicompat\deflang1033{\fonttbl{\f0\fnil\fcharset0 Calibri;}{\f1\fnil Calibri;}}
{\colortbl ;\red0\green0\blue255;}
{\*\generator Riched20 10.0.17763}\viewkind4\uc1 
\pard\sa200\sl240\slmult1\f0\fs22\lang9 Docker Certified Associate\par
Contents\par
Docker Community Edition Installation and Configuration 1\par
Installing Docker on CentOS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\par
Installing Docker on Ubuntu . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\par
Selecting a Storage Driver . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\par
Storage Driver Basics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\par
Using a Daemon Flag to Set the Storage Driver . . . . . . . . . . . . . . . . . . . . . 3\par
Using the Daemon Config File to Set the Storage Driver . . . . . . . . . . . . . . . . . 3\par
Running a Container . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\par
Docker Run . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\par
Managing Containers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\par
Upgrading the Docker Engine . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\par
Configuring Logging Drivers (Splunk, Journald, etc.) . . . . . . . . . . . . . . . . . . . . . . . 6\par
Introduction to Docker Swarm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\par
Configuring a Swarm Manager . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\par
Configuring Swarm Nodes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\par
Docker Swarm Backup and Restore . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\par
Backup Swarm Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\par
Restore from Backup . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\par
Namespaces and Cgroups . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\par
Image Creation, Management, and Registry 9\par
Introduction to Docker Images . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\par
The Components of a Dockerfile . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\par
More Dockerfile Directives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\par
Building Efficient Images . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\par
1\par
Managing Images . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\par
Flattening a Docker Image to a Single Layer . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\par
Introduction to Docker Registries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\par
Using Docker Registries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\par
Orchestration 14\par
Locking and Unlocking a Swarm Cluster . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\par
High Availability in a Swarm Cluster . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\par
Introduction to Docker Services . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\par
Using docker inspect . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\par
Docker Compose . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\par
Introduction to Docker Stacks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\par
Node Labels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\par
Storage and Volumes 19\par
Docker Storage in Depth . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\par
Storage Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\par
Configuring the Device Mapper . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\par
Docker Volumes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\par
-v syntax . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\par
\f1\endash mount syntax . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\par
Image Cleanup . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\par
Storage in a Cluster . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\par
Networking 23\par
Docker Networking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\par
Built-In Network Drivers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\par
Host . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\par
2\par
Bridge . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\par
Overlay . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\par
MACVLAN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\par
None . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\par
Creating a Docker Bridge Network . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\par
Deploying a Service on a Docker Overlay Network . . . . . . . . . . . . . . . . . . . . . . . . 26\par
Exposing Containers Externally . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\par
Network Troubleshooting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\par
Configuring Docker to Use External DNS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\par
Security 28\par
Signing Images and Enabling Docker Content Trust . . . . . . . . . . . . . . . . . . . . . . . 28\par
Default Docker Engine Security . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\par
Docker MTLS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\par
Securing the Docker Daemon HTTP Socket . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\par
Using Docker Enterprise Edition 30\par
Installing Docker EE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\par
Setting up Universal Control Plane (UCP) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\par
Security in UCP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\par
Setting Up Docker Trusted Registry (DTR) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\par
Sizing Requirements for Docker, UCP, and DTR . . . . . . . . . . . . . . . . . . . . . . . . . . 34\par
Configuring Backups for UCP and DTR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\par
Back Up the UCP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\par
Restore UCP from Backup . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\par
Back Up the DTR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\par
Restore DTR Backup . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\par
DTR Security Features . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\par
Managing Certificates with UCP and DTR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\par
4\par
Docker Certified Associate Linux Academy\par
Docker Community Edition Installation and\par
Configuration\par
Installing Docker on CentOS\par
Documentation:\par
Docker CE for CentOS Setup Requirements\par
Here is a basic guide that covers on how to install Docker CE on CentOS 7:\par
1. Install the required packages:\par
sudo yum install -y () \\\par
device-mapper-persistent-data \\\par
lvm2\par
2. Add the Docker CE yum repository:\par
sudo yum-config-manager \\\par
--add-repo \\\par
{{\field{\*\fldinst{HYPERLINK https://download.docker.com/linux/centos/docker-ce.repo }}{\fldrslt{https://download.docker.com/linux/centos/docker-ce.repo\ul0\cf0}}}}\f1\fs22\par
3. Install the Docker CE packages:\par
sudo yum install -y docker-ce-18.09.5 docker-ce-cli-18.09.5 containerd.io\par
4. Start and enable the Docker service:\par
sudo systemctl start docker\par
sudo systemctl enable docker\par
To grant a user permission to run Docker commands, add the user to the Docker group. The user will\par
have access to Docker after their next login.\par
sudo usermod -a -G docker <user>\par
We can test our Docker installation by running a simple container. This container should output some\par
text, and then exit.\par
docker run hello-world\par
1\par
Docker Certified Associate Linux Academy\par
Installing Docker on Ubuntu\par
Documentation:\par
Docker CE Install Link\par
Here is a basic guide to installing Docker CE on Ubuntu:\par
1. Install the required packages:\par
sudo apt-get update\par
sudo apt-get -y install \\\par
apt-transport-https \\\par
ca-certificates \\\par
curl \\\par
gnupg-agent \\\par
software-properties-common\par
2. Add the Docker repo\rquote s GNU Privacy Guard (GPG) key:\par
curl -fsSL {{\field{\*\fldinst{HYPERLINK https://download.docker.com/linux/ubuntu/gpg }}{\fldrslt{https://download.docker.com/linux/ubuntu/gpg\ul0\cf0}}}}\f1\fs22  | sudo apt-key add -\par
It\rquote s a good idea to verify the key fingerprint. This is an optional step, but highly recommended. We should\par
receive an output indicating that the key was found:\par
sudo apt-key fingerprint 0EBFCD88\par
3. Add the Docker Ubuntu repository:\par
sudo add-apt-repository \\\par
"deb [arch=amd64] {{\field{\*\fldinst{HYPERLINK https://download.docker.com/linux/ubuntu }}{\fldrslt{https://download.docker.com/linux/ubuntu\ul0\cf0}}}}\f1\fs22  \\\par
$(lsb_release -cs) \\\par
stable"\par
4. Install packages:\par
sudo apt-get update\par
sudo apt-get install -y docker-ce=5:18.09.5~3-0~ubuntu-bionic \\\par
docker-ce-cli=5:18.09.5~3-0~ubuntu-bionic containerd.io\par
5. To provide a user with permission to run Docker commands, add the user to the Docker group. The\par
user will have access to Docker after their next login.\par
sudo usermod -a -G docker <user>\par
6. We can test our Docker installation by running a simple container. This container should output\par
some text, and then exit.\par
docker run hello-world\par
2\par
Docker Certified Associate Linux Academy\par
Selecting a Storage Driver\par
Documentation:\par
Docker Storage Drivers Overview Link\par
Storage Driver Basics\par
Storage Driver: A pluggable driver that handles internal storage for containers.\par
Currently, the default driver for CentOS and Ubuntu systems is overlay2.\par
The devicemapper storage driver is sometimes used on CentOS/RedHat systems, especially in older Docker\par
versions.\par
We can determine the current storage driver with docker info:\par
docker info | grep "Storage"\par
Using a Daemon Flag to Set the Storage Driver\par
One way to select a different storage driver is to pass the --storage-driver flag over to the Docker\par
daemon.\par
For example, we can modify Docker\rquote s systemd unit file: /usr/lib/systemd/system/docker.service.\par
Remember, add the flag --storage-driver <driver name> to the call to dockerd.\par
Using the Daemon Config File to Set the Storage Driver\par
Note: This is the recommended method for setting the storage driver.\par
1. Create or edit /etc/docker/daemon.json:\par
sudo vi /etc/docker/daemon.json\par
2. Add the value "storage-driver": "<driver name>":\par
This example sets the storage driver to devicemapper.\par
\{\par
"storage-driver": "devicemapper"\par
\}\par
3\par
Docker Certified Associate Linux Academy\par
3. After any changes are made to /etc/docker/daemon.json, remember to restart Docker. It is also\par
a good idea to check the status of Docker after restarting, as a malformed config file will cause\par
Docker to encounter startup failure. Use the following commands:\par
sudo systemctl restart docker\par
sudo systemctl status docker\par
Running a Container\par
Documentation:\par
Docker Run Reference Link\par
Docker Run\par
Here are some key commands and processes:\par
docker run IMAGE[:TAG] [COMMAND] [ARGS] : Runs a container.\par
\bullet  IMAGE: Run a container using an image called hello-world. In this example, the tag is unspecified,\par
so the latest tag will automatically be used.\par
docker run hello-world\par
\bullet  COMMAND and ARGS: Run a command inside the container. This command runs a container using\par
the busybox image. Inside the container, plus it runs the command echo with the arguments hello\par
world!.\par
docker run busybox echo hello world!\par
\bullet  TAG: This command specifies a certain tag, running a container with tag 1.15.11 of the nginx image.\par
docker run nginx:1.15.11\par
\bullet  -d: Runs the container in detached mode. The command immediately exits, and the container\par
continues to run in the background.\par
\bullet  \endash name NAME: Gives the container a specified name instead of the usual randomly-assigned name.\par
\bullet  \endash restart RESTART: Specifies when Docker should automatically restart the container.\par
Valid values include:\par
\bullet  no (default): Never restart the container.\par
4\par
Docker Certified Associate Linux Academy\par
\bullet  on-failure: Only if the container fails (exits with a non-zero exit code).\par
\bullet  always: Always restart the container whether it succeeds or fails. Also starts the container automatically upon daemon startup.\par
\bullet  unless-stopped: Always restart the container whether it succeeds or fails, and on daemon startup\par
unless the container is manually stopped.\par
\bullet  -p HOST_PORT:CONTAINER_PORT: Publish a container\rquote s port. This process is necessary to access a\par
port on a running container. The HOST_PORT is the port that listens on the host machine, and traffic\par
to that port is mapped to the CONTAINER_PORT on the container.\par
\bullet  \endash memory MEMORY: Set a hard limit on memory usage.\par
\bullet  \endash memory-reservation MEMORY: Set a soft limit on memory usage. This limit is used only if Docker\par
detects memory contention on the host.\par
Here\rquote s an example of these docker run flags in action:\par
docker run -d --name nginx --restart unless-stopped -p 8080:80 --memory 500M \\\par
--memory-reservation 256M nginx\par
Managing Containers\par
Some of the commands for managing running containers:\par
\bullet  docker ps: List running containers.\par
\bullet  docker ps -a: List all containers, including stopped containers.\par
\bullet  docker container stop <container name or ID>: Stop a running container.\par
\bullet  docker container start <container name or ID>: Start a stopped container.\par
\bullet  docker container rm <container name or ID>: Delete a container (must be stopped first).\par
Upgrading the Docker Engine\par
Documentation:\par
Upgrade Docker CE Link\par
1. To upgrade the Docker engine, first we must stop the Docker service and install newer versions of\par
docker-ce and docker-ce-cli.\par
sudo systemctl stop docker\par
sudo apt-get install -y docker-ce=<new version> docker-ce-cli=<new version>\par
2. Check the current version:\par
docker version\par
5\par
Docker Certified Associate Linux Academy\par
Configuring Logging Drivers (Splunk, Journald, etc.)\par
Documentation:\par
Logging Drivers Configuration Link\par
Logging driver: A pluggable driver that handles log data from services and containers in Docker.\par
Determine the current default logging driver:\par
docker info | grep Logging\par
To set a new default driver, modify /etc/docker/daemon.json. The log-driver option sets the driver, and\par
log-opts can be used to provide driver-specific configuration.\par
For example:\par
\{\par
"log-driver": "json-file",\par
"log-opts": \{\par
"max-size": "10m",\par
"max-file": "3",\par
"labels": "production_status",\par
"env": "os,customer"\par
\}\par
\}\par
Remember to utilize sudo systemctl restart docker after making any changes to /etc/docker/daemon.json.\par
We can also override the default driver setting for individual containers using the --log-driver' and\par
'--log-opt flags with docker run.\par
docker run --log-driver json-file --log-opt max-size=10m nginx\par
Introduction to Docker Swarm\par
Documentation:\par
Swarm Mode Concepts Link\par
Docker Swarm: A cluster management solution that comes packaged with Docker. It allows us to create\par
and manage a cluster of Docker servers.\par
Manager: A server in a Swarm that controls the swarm cluster and delegates work to workers.\par
Worker: A server in the Swarm that executes container workloads.\par
6\par
Docker Certified Associate Linux Academy\par
Configuring a Swarm Manager\par
Documentation:\par
Swarm Creation Link\par
1. First, install Docker CE on the machine (refer to the prior sections on installing Docker CE).\par
2. Initialize the swarm:\par
Note: Set --advertise-addr to an address that other nodes in the swarm will see this node as.\par
docker swarm init --advertise-addr <advertise address>\par
We can find information about the current state of the swarm using docker info.\par
3. List nodes in the swarm:\par
Note: At this point there will only be one because the manager that was just initialized.\par
docker node ls\par
Configuring Swarm Nodes\par
Documentation:\par
Adding Swarm Nodes Link\par
1. First, install Docker CE on the machine (refer to the prior sections on installing Docker CE).\par
2. Retrieve a join-token from the manager.\par
3. Run this command on the Swarm manager:\par
docker swarm join-token worker\par
4. Now copy the docker swarm join command provided in the output and run it on all workers.\par
The command\rquote s execution looks like this:\par
docker swarm join --token <token> <swarm manager private IP>:2377\par
5. On the Swarm Manager, verify that all of the worker nodes have successfully joined.\par
docker node ls\par
All nodes should appear in the list, including the manager.\par
7\par
Docker Certified Associate Linux Academy\par
Docker Swarm Backup and Restore\par
Documentation:\par
Administration and Back up the Swarm Link\par
Backup Swarm Data\par
On the manager:\par
1. Stop Docker:\par
sudo systemctl stop docker\par
2. Archive the swarm data located in /var/lib/docker/swarm, and then start Docker again.\par
sudo tar -zvcf backup.tar.gz /var/lib/docker/swarm\par
sudo systemctl start docker\par
Restore from Backup\par
Perform the following steps on the manager:\par
1. Stop Docker:\par
sudo systemctl stop docker\par
2. Delete any data currently in the swarm data directory:\par
sudo rm -rf /var/lib/docker/swarm/*\par
3. Expand the archived backup data into the swarm data directory and start Docker:\par
sudo tar -zxvf backup.tar.gz -C /var/lib/docker/swarm/\par
sudo systemctl start docker\par
4. Verify that all of the nodes are functioning properly in the swarm after the restore:\par
docker node ls\par
8\par
Docker Certified Associate Linux Academy\par
Namespaces and Cgroups\par
Documentation:\par
Docker Overview Link\par
Namescape Remapping Link\par
Namespaces: A Linux related technology that isolates processes by partitioning the resources that are\par
available to them. Namespaces prevent processes from interfering with one another. Docker leverages\par
namespaces to isolate resources for containers.\par
Some namespaces used by Docker:\par
\bullet  pid: Process isolation.\par
\bullet  net: Network interfaces.\par
\bullet  ipc: Inter-process communication.\par
\bullet  mnt: Filesystem mounts.\par
\bullet  uls: Kernel and version identifiers.\par
\bullet  user namespaces: Requires special configuration. Allows container processes to run as root inside\par
the container while mapping that user to an unprivileged user on the host.\par
Control Groups (cgroups): Control groups limit processes to a specific set of resources. Docker uses\par
cgroups to enforce rules around resource usage by containers, such as limiting memory or CPU usage.\par
Image Creation, Management, and Registry\par
Introduction to Docker Images\par
Documentation:\par
Images, Containers, and Storage Drivers Link\par
Image: An executable package containing all of the software that\rquote s needed to run a container.\par
Run a container using an image with:\par
docker run IMAGE\par
Download an image with:\par
9\par
Docker Certified Associate Linux Academy\par
docker image pull IMAGE\par
docker pull IMAGE\par
Layered File System: Images and containers use a layered file system. Each layer contains only the\par
differences from the previous layer.\par
View file system layers in an image with:\par
docker image history IMAGE\par
The Components of a Dockerfile\par
Documentation:\par
Dockerfile Builds Reference Link\par
Dockerfile: A file that defines a series of directives and is used to build an image.\par
An example of a Dockerfile:\par
# Simple nginx image\par
FROM ubuntu:bionic\par
ENV NGINX_VERSION 1.14.0-0ubuntu1.2\par
RUN apt-get update && apt-get install -y curl\par
RUN apt-get update && apt-get install -y nginx=$NGINX_VERSION\par
CMD ["nginx", "-g", "daemon off;"]\par
Build an image with:\par
docker build -t TAG_NAME DOCKERFILE_LOCATION\par
Dockerfile Directives:\par
\bullet  FROM: Specifies the base image to build from.\par
\bullet  ENV: Sets environment variables that are visible in later build steps as well as during container runtime.\par
\bullet  RUN: Executes a command and commits the result to the image file system.\par
\bullet  CMD: Sets the default command for containers, and this gets overridden if a command gets specified\par
at container runtime.\par
\bullet  ENTRYPOINT: Sets the default executable for containers. This can still be overridden at container\par
runtime, but requires a special flag. When ENTRYPOINT and CMD are both used, ENTRYPOINT sets the\par
default executable, and CMD sets default arguments.\par
10\par
Docker Certified Associate Linux Academy\par
More Dockerfile Directives\par
Documentation:\par
Dockerfile Builds Reference Link\par
Directives:\par
\bullet  EXPOSE: Documents ports that are intended to be published at runtime.\par
Note: that this does not actually publish the ports.\par
\bullet  WORKDIR: Sets the working directory, both for subsequent build steps and for the container at runtime. We can use WORKDIR multiple times. If the WORKDIR begins with a forward slash /, then it will\par
set an absolute path. Otherwise, it will set the working directory relative to the previous working\par
directory.\par
\bullet  COPY: Copies files from the build host into the image file system.\par
\bullet  ADD: Copies files from the build host into the image file system. Unlike COPY, ADD can also extract an\par
archive into the image file system and add files from a remote URL.\par
\bullet  STOPSIGNAL: Sets a custom signal that will be used to stop the container process.\par
\bullet  HEALTHCHECK: Sets a command that will be used by the Docker daemon to check whether the container is healthy.\par
Building Efficient Images\par
Documentation:\par
Best Practices for Dockerfiles Link\par
Using Multi-stage Builds Link\par
Multi-Stage Build: A build from a Dockerfile with more than one FROM directive. It is used to selectively\par
copy files into the final stage, keeping the resulting image as small as possible.\par
Managing Images\par
Documentation:\par
Docker Image Commands Link\par
Here are some key commands for image management:\par
\bullet  docker image ls: List images on the system.\par
\bullet  docker image ls -a: Includes intermediate images.\par
11\par
Docker Certified Associate Linux Academy\par
\bullet  docker image inspect IMAGE: Get detailed information about an image.\par
\bullet  docker image inspect IMAGE --format "GO_TEMPLATE": Provide a Go template to retrieve specific\par
data fields about the image.\par
\bullet  docker image rm IMAGE: Delete an image. An image can only face deletion if no containers or other\par
image tags reference it.\par
\bullet  docker rmi IMAGE: Delete an image.\par
\bullet  docker image rm -f IMAGE: Force deletion of an image, even if gets referenced by something else.\par
\bullet  docker image prune: Find and delete dangling or unused images.\par
Flattening a Docker Image to a Single Layer\par
Docker does not provide an official method for turning a multi-layered image into a single layer. We can\par
work around this by running a container from the image, exporting the container\rquote s file system, and then\par
importing that data as a new image.\par
1. Set up a new project directory to create a basic image:\par
cd ~/\par
mkdir alpine-hello\par
cd alpine-hello\par
vi Dockerfile\par
2. Create a Dockerfile that will result in a multi-layered image:\par
FROM alpine:3.9.3\par
RUN echo "Hello, World!" > message.txt\par
CMD cat message.txt\par
3. Build the image and check how many layers it has:\par
docker build -t nonflat .\par
docker image history nonflat\par
4. Run a container from the image and export its file system to an archive:\par
docker run -d --name flat_container nonflat\par
docker export flat_container > flat.tar\par
5. Import the archive to a new image and check how many layers the new image has:\par
cat flat.tar | docker import - flat:latest\par
docker image history flat\par
12\par
Docker Certified Associate Linux Academy\par
Introduction to Docker Registries\par
Documentation:\par
Registry Deployment Link\par
Registry Configuration Link\par
Insecure Registry Testing Link\par
Docker Registry: A central location for storing and distributing images.\par
Docker Hub: The default, public registry that\rquote s operated by Docker.\par
We can operate our own private registry for free using the registry image.\par
Run a simple registry with:\par
docker run -d -p 5000:5000 --restart=always --name registry registry:2\par
Configure our registry using environment variables with:\par
docker run -d -p 5000:5000 --restart=always --name registry \\\par
-e REGISTRY_LOG_LEVEL=debug registry:2\par
Using Docker Registries\par
Documentation:\par
Docker Push Commands Link\par
Docker Pull Commands Link\par
Docker Login Commands Link\par
Insecure Registry Testing Link\par
Docker Search Commands Link\par
We can search Docker Hub from the command line with:\par
docker search SEARCH_TERM\par
Authenticate against a registry. We can omit the REGISTRY_URL to authenticate with Docker Hub:\par
docker login REGISTRY_URL\par
13\par
Docker Certified Associate Linux Academy\par
There are two ways to authenticate with a private registry that uses an untrusted or self-signed certificate.\par
\bullet  Secure: Adds the registry\rquote s public certificate to /etc/docker/certs.d/<registry public hostname>.\par
\bullet  Insecure: Adds the registry to the insecure-registries list in daemon.json, or pass it to dockerd\par
with the --insecure-registry flag.\par
Push an image to a registry:\par
docker push IMAGE\par
Orchestration\par
Locking and Unlocking a Swarm Cluster\par
Documentation:\par
Docker Swarm Protection Link\par
Autolock: A feature of Docker Swarm. Prevents sensitive keys from being stored insecurely on swarm\par
managers, but requires us to enter an unlock key whenever the Docker daemon restarts on a swarm\par
manager.\par
1. The command that enables the autolock feature:\par
docker swarm update --autolock=true\par
2. The command that disables the autolock feature:\par
docker swarm update --autolock=false\par
3. The command that unlocks a locked Swarm manager:\par
docker swarm unlock\par
4. To obtain the unlock key from an unlocked Swarm manager:\par
docker swarm unlock-key\par
5. To rotate the unlock key, which will automatically orchestrate key rotation across all nodes in the\par
cluster:\par
docker swarm unlock-key --rotate\par
14\par
Docker Certified Associate Linux Academy\par
High Availability in a Swarm Cluster\par
Documentation:\par
Swarm of Docker Engines Administration Link\par
Raft Consensus Link\par
To make our swarm cluster highly available, we must use multiple manager nodes.\par
Swarm managers use a consensus algorithm to maintain consistent data about the swarm state across\par
all nodes. This algorithm requires that a quorum be maintained for changes to be made to the cluster.\par
Quorum: The majority (more than half) of the manager nodes in our swarm.\par
To achieve quorum, more than half of the total amount of nodes in our swarm must be available and\par
communicate with the other available nodes.\par
Remember if exactly half of our nodes are available, this does not count as a quorum. We must have\par
more than half.\par
Availability Zones: Different datacenters or different areas of the same datacenter. By spreading nodes\par
across multiple availability zones, we\rquote ll ensure that we can maintain a functional cluster even if some\par
component of our infrastructure fails.\par
To ensure maximum availability, spread the manager nodes across availability zones so that if any of the\par
zones go down, we can still maintain a quorum. For example:\par
Number of Manager nodes Availability Zone Distribution\par
3 1-1-1\par
5 2-2-1\par
7 3-2-2\par
9 3-3-3\par
Introduction to Docker Services\par
Documentation:\par
Swarm Service Deployment Link\par
Services Overview Link\par
Service Creation Link\par
Service: A collection of one or more replica containers running the same image in a swarm.\par
Task: A replica container that is running as part of a service.\par
Here are some common tasks and the commands that are associated with them:\par
15\par
Docker Certified Associate Linux Academy\par
1. Create a service with:\par
docker service create IMAGE\par
2. To provide a name for a service, we can use:\par
docker service create --name NAME IMAGE\par
3. Set the number of replicas with:\par
docker service create --replicas REPLICAS IMAGE\par
4. Publish a port for the service. By default, the port will listen on all nodes in the cluster (workers\par
and managers). Requests can be routed to a container on any node, regardless of which node is\par
accessed by the client. The format will look like this:\par
docker service create -p 8080:80 IMAGE\par
Note: We can use templates to pass dynamic data to certain flags when creating a service, for\par
instance this example sets an environment variable containing the node hostname for each replica\par
container.\par
docker service create --name node-hostname --replicas 3 --env NODE_HOSTNAME="\{\{.Node.Hostname\}\}" \\\par
nginx\par
5. We can list services in the cluster with:\par
docker service ls\par
6. We can list the tasks/containers for a service with:\par
docker service ps SERVICE\par
7. To inspect a service:\par
docker service inspect SERVICE\par
docker service inspect --pretty SERVICE\par
8. To change a service:\par
docker service update --replicas 2 SERVICE\par
9. There are two different ways to change the number of replicas for a service:\par
docker service update --replicas 2 SERVICE\par
docker service scale SERVICE=REPLICAS\par
10. Delete a service with:\par
docker service rm SERVICE\par
11. We can create global services. Instead of running a specific number of replicas, they run exactly\par
one task on each node in the cluster. The command appears as:\par
docker service create --mode global IMAGE\par
16\par
Docker Certified Associate Linux Academy\par
Using docker inspect\par
Documentation:\par
Swarm Service Deployment Link\par
Services Overview Link\par
Service Creation and Commands Link\par
Docker inspect provides a way to get detailed information about Docker objects. We can use the general\par
form docker inspect OBJECT or an object-type-specific form docker container inspect CONTAINER.\par
Use the --format flag with Docker inspect to retrieve specific data fields using a Go template:\par
docker service inspect --format='\{\{.ID\}\}' SERVICE\par
Docker Compose\par
Documentation:\par
Docker Compose Link\par
Docker Compose: A tool used to manage complex, multi-container applications running on a single host.\par
To use Docker Compose, first define the application in a compose file.\par
An example of a simple docker-compose.yml:\par
version: '3'\par
services:\par
web:\par
image: nginx\par
ports:\par
- "8080:80"\par
redis:\par
image: redis:alpine\par
Run an application using a compose file from the directory where the file is located:\par
docker-compose up -d\par
List compose applications:\par
docker-compose ps\par
17\par
Docker Certified Associate Linux Academy\par
Stop a Docker compose application from the directory where the compose file is located:\par
docker-compose down\par
Introduction to Docker Stacks\par
Documentation:\par
Stacks and Prerequisites Link\par
Docker Stack Commands Link\par
Stack: A complex, multi-service application running in a swarm.\par
We can define a stack using a Docker Compose file, and then run it in the swarm with:\par
docker stack deploy -c COMPOSE_FILE STACK_NAME\par
Remember that we can redeploy the stack with the same compose file to make changes to it.\par
Delete a stack with:\par
docker stack rm STACK\par
Node Labels\par
Documentation:\par
Docker Node Update Link\par
Placement Constraints Link\par
Node Label: Custom metadata about a node in the cluster.\par
To list current nodes, enter:\par
docker node ls\par
To add a label to a node, input:\par
docker node update --label-add LABEL_NAME=LABEL_VALUE NODE\par
To view existing labels, run:\par
18\par
Docker Certified Associate Linux Academy\par
docker node inspect --pretty NODE\par
We can use node constraints to control which nodes a service\rquote s tasks will run on based upon node labels.\par
Here is an example:\par
docker service create --constraint node.labels.availability_zone==east nginx\par
To use various expressions for constraints, such as inequality, we can run, for instance:\par
--constraint node.labels.availability_zone!=east\par
Use --placement-pref to spread tasks evenly based on the value of a specific label:\par
docker service create --placement-pref spread=node.labels.availability_zone --replicas 3 nginx\par
Storage and Volumes\par
Docker Storage in Depth\par
Documentation:\par
Docker Storage Drivers Link\par
Object Storage and File Systems Link\par
Here are what default storage drivers consist of in terms of systems:\par
\bullet  Latest versions of Ubuntu and CentOS \emdash  overlay2\par
\bullet  CentOS 7 and earlier \emdash  devicemapper\par
\bullet  Ubuntu 14.04 and earlier - aufs\par
Storage Models\par
Filesystem Storage:\par
\bullet  Data is stored in the form of regular files on the host disk.\par
\bullet  Used by overlay2 and aufs.\par
\bullet  Efficient use of memory.\par
19\par
Docker Certified Associate Linux Academy\par
\bullet  Inefficient with write-heavy workloads.\par
\bullet  Block Storage:\par
\bullet  Stores data in blocks using special block storage devices.\par
\bullet  Used by devicemapper.\par
\bullet  Efficient with write-heavy workloads.\par
\bullet  Object Storage:\par
\bullet  Stores data in an external object-based store.\par
\bullet  Application must be designed to use object-based storage.\par
\bullet  Flexible and scalable.\par
We can inspect containers and images to locate the actual location of their data files on disk.\par
Configuring the Device Mapper\par
Documentation:\par
Device Mapper Storage Driver\par
devicemapper: A block storage driver used by CentOS 7 and earlier.\par
Uses two modes:\par
\bullet  loop-lvm: This is the default mode, but it is recommended for testing only, not for production use.\par
\bullet  direct-lvm: A production-ready mode, which requires additional configuration and a special block\par
storage device.\par
Below is sample configuration to enable direct-lvm in daemon.json.\par
Remember, this assumes that there is a block storage device called `/dev/xvdb`.\par
\{\par
"storage-driver": "devicemapper",\par
"storage-opts": [\par
"dm.directlvm_device=/dev/xvdb",\par
"dm.thinp_percent=95",\par
"dm.thinp_metapercent=1",\par
"dm.thinp_autoextend_threshold=80",\par
"dm.thinp_autoextend_percent=20",\par
"dm.directlvm_device_force=true"\par
]\par
\}\par
20\par
Docker Certified Associate Linux Academy\par
Docker Volumes\par
Documentation:\par
Managing Data Storage Link\par
Using Bind Mounts Link\par
Using Volumes Link\par
There are two different types of data mounts on Docker:\par
\bullet  Bind Mount: Mounts a specific directory on the host to the container. It is useful for sharing configuration files, plus other data between the container and host.\par
\bullet  Named Volume: Mounts a directory to the container, but Docker controls the location of the volume\par
on disk dynamically.\par
There are different syntaxes for adding bind mounts or volumes to containers:\par
-v syntax\par
A bind mount. The fact that the source begins with a forward slash / makes this a bind mount.\par
docker run -v /opt/data:/tmp nginx\par
A named volume. The fact that the source is just a string means that this is a volume. If no volume exists\par
with the provided name, then it will be automatically created.\par
docker run -v my-vol:/tmp nginx\par
\endash mount syntax\par
A bind mount:\par
docker run --mount source=/opt/data,destination=/tmp nginx\par
A named volume:\par
docker run --mount source=my-vol,destination=/tmp nginx\par
21\par
Docker Certified Associate Linux Academy\par
We can mount the same volume to multiple containers, allowing them to share data.\par
We can also create and manage volumes by themselves without running a container.\par
Here are some common and useful commands:\par
\bullet  docker volume create VOLUME: Creates a volume.\par
\bullet  docker volume ls: Lists volumes.\par
\bullet  docker volume inspect VOLUME: Inspects a volume.\par
\bullet  docker volume rm VOLUME: Deletes a volume.\par
Image Cleanup\par
Documentation:\par
Docker System DF Link\par
To display Docker\rquote s disk usage on a system, enter:\par
docker system df\par
To display a more detailed disk usage report, input:\par
docker system df -v\par
To delete dangling/unused images, run:\par
docker image prune\par
Once we have verified that the images are not being used by a container, we can use the following command to delete all of them:\par
docker image prune -a\par
Storage in a Cluster\par
Documentation:\par
Sharing Data Among Machines Link\par
22\par
Docker Certified Associate Linux Academy\par
Swarm clusters present special challenges when we want to share volumes between multiple containers.\par
If the containers are running on different nodes, then they still need to be able to access the shared data.\par
vieux/sshfs plugin: Provides a volume driver that interacts with remote storage using SSH, allowing the\par
storage to be accessed from multiple nodes.\par
1. Install the plugin:\par
docker plugin install --grant-all-permissions vieux/sshfs\par
2. Create a service that uses the vieux/sshfs volume driver to provide shared storage between its\par
containers:\par
docker service create \\\par
--replicas=3 \\\par
--name storage-service \\\par
--mount volume-driver=vieux/sshfs,source=cluster-volume,destination=/app, \\\par
volume-opt=sshcmd=cloud_user@<storage \\\par
server private IP>:/home/cloud_user/external,volume-opt=password=<password> busybox cat \\\par
/app/message.txt\par
Networking\par
Docker Networking\par
Documentation:\par
Docker Container Networks Link\par
Docker Container Networking Model (CNM): A conceptual model that describes the components and\par
concepts of Docker networking.\par
There are multiple implementations of the Docker CNM:\par
\bullet  Sandbox: An isolated unit containing all networking components associated with a single container.\par
\bullet  Endpoint: Connects one sandbox to one network.\par
\bullet  Network: A collection of endpoints that can communicate with each other.\par
\bullet  Network Driver: A pluggable driver that provides a specific implementation of the CNM.\par
\bullet  IPAM Driver: Provides IP Address management. Allocates and assigns IP addresses.\par
23\par
Docker Certified Associate Linux Academy\par
Built-In Network Drivers\par
Documentation:\par
Docker Network Drivers Overview Link\par
Use Cases for Docker Network Drivers\par
Native Network Drivers: Network drivers that come shipped with Docker.\par
Host\par
This driver connects the container directly to the host\rquote s networking stack. It provides no isolation between\par
containers or between containers and the host.\par
docker run --net host nginx\par
Bridge\par
This driver uses virtual bridge interfaces to establish connections between containers running on the\par
same host.\par
docker network create --driver bridge my-bridge-net\par
docker run -d --network my-bridge-net nginx\par
Overlay\par
This driver uses a routing mesh to connect containers across multiple Docker hosts, usually in a Docker\par
swarm.\par
docker network create --driver overlay my-overlay-net\par
docker service create --network my-overlay-net nginx\par
MACVLAN\par
This driver connect containers directly to the host\rquote s network interfaces, but uses special configuration to\par
provide isolation.\par
docker network create -d macvlan --subnet 192.168.0.0/24 --gateway 192.168.0.1 -o parent=eth0 \\\par
my-macvlan-net\par
docker run -d --net my-macvlan-net nginx\par
24\par
Docker Certified Associate Linux Academy\par
None\par
This driver provides sandbox isolation, but it does not provide any implementation for networking between containers or between containers and the host.\par
docker run --net none -d nginx\par
Creating a Docker Bridge Network\par
Documentation:\par
Using Bridge Networks Link\par
Bridge is the default driver, so any network that is created without specifying the driver will be a bridge\par
network.\par
Create a bridge network:\par
docker network create my-net\par
Run a container on the bridge network:\par
docker run -d --network my-net nginx\par
By default, container and services on the same network can communicate with each other simply using\par
their container or service names. Docker provides DNS resolution on the network that allows this to work.\par
We can supply a network alias to provide an additional name by which a container or service is reached.\par
docker run -d --network my-net --network-alias my-nginx-alias nginx\par
Here are some useful commands for when one must interact with Docker networks:\par
\bullet  docker network ls: Lists networks.\par
\bullet  docker network inspect NETWORK: Inspects a network.\par
\bullet  docker network connect CONTAINER NETWORK: Connects a container to a network.\par
\bullet  docker network disconnect CONTAINER NETWORK: Disconnects a container from a network.\par
\bullet  docker network rm NETWORK: Deletes a network.\par
25\par
Docker Certified Associate Linux Academy\par
Deploying a Service on a Docker Overlay Network\par
Documentation:\par
Using Overlay Networks Link\par
To create an overlay network, run:\par
docker network create --driver overlay NETWORK_NAME\par
To create a service that uses the network, enter:\par
docker service create --network NETWORK_NAME IMAGE\par
Exposing Containers Externally\par
Documentation:\par
Docker Run Commands Link\par
Docker Service Command Options Link\par
Docker Port Commands Link\par
Publish a port on a container. The host port is the port that will listen on the host. Requests to that port\par
on the host will be forwarded to the CONTAINER_PORT inside the container.\par
docker run -d -p HOST_PORT:CONTAINER_PORT IMAGE\par
*-P, --publish-all: Publish all ports documented using EXPOSE for the image. These ports are all published to random ports.\par
We can also publish ports for services. By default, the routing mesh causes the host port to listen on all\par
nodes in the cluster. Requests can be forwarded to any task, even if they are on another node.\par
docker service create -p HOST_PORT:CONTAINER_PORT IMAGE\par
We can publish service ports in host mode. This mode is much more restrictive. It does not use a routing\par
mesh. Requests to the host port on a host are forwarded to the task running on that same host. Therefore, in this mode, we cannot have more than one task for the service per host, and hosts that are not\par
running a task for the service won\rquote t listen on the host port.\par
docker service create -p mode=host,published=HOST_PORT,target=CONTAINER_PORT IMAGE\par
26\par
Docker Certified Associate Linux Academy\par
Network Troubleshooting\par
Documentation:\par
Troubleshooting Container Networking Link\par
To view container logs, enter:\par
docker logs CONTAINER\par
To view logs for all tasks of a service, execute:\par
docker service logs SERVICE\par
To view Docker daemon logs, input:\par
sudo jounralctl -u docker\par
We can use the nicolaka/netshoot image to perform network troubleshooting. It comes packaged with\par
a variety of useful networking-related tools.\par
We can inject a container into another container\rquote s networking sandbox for troubleshooting purposes:\par
docker run --network container:CONTAINER_NAME nicolaka/netshoot\par
Configuring Docker to Use External DNS\par
Documentation:\par
Container DNS Configuration Link\par
Daemon DNS Options Link\par
We can customize the DNS server that will be used by our containers.\par
Set the system-wide default DNS for Docker containers in daemon.json:\par
\{\par
"dns": ["8.8.8.8"]\par
\}\par
Set the DNS for an individual container.\par
docker run --dns 8.8.4.4 IMAGE\par
27\par
Docker Certified Associate Linux Academy\par
Security\par
Signing Images and Enabling Docker Content Trust\par
Documentation:\par
Content Trust in Docker Link\par
Docker Content Trust (DCT): A feature that allows us to sign images and verify signatures before running\par
them.\par
Enable Docker Content Trust by setting an environment variable: DOCKER_CONTENT_TRUST=1. With Docker\par
Content Trust enabled, the system will not run images if they are unsigned or the signature is not valid.\par
We can sign and push an image with:\par
docker trust sign\par
With DOCKER_CONTENT_TRUST=1, docker push automatically signs the image before pushing it.\par
Default Docker Engine Security\par
Documentation:\par
Docker Security Link\par
Some basic Docker Security concepts:\par
\bullet  Docker uses namespaces to isolate container processes from one other and the host. This prevents\par
an attacker from affecting or gaining control of other containers or the host if they manage to gain\par
control of one container.\par
\bullet  The Docker daemon must run with root access. Additionally, be aware of this before allowing anything or anyone to interact with the daemon. It could be used to gain access to the entire host.\par
\bullet  Docker leverages Linux capabilities to assign granular permissions to container processes. For\par
example, listening on a low port (below 1024) usually requires a process to run as root, but Docker\par
uses Linux capabilities to allow a container to listen on port 80 without running as root.\par
Docker MTLS\par
Documentation:\par
Managing Swarm Security with Public Key Infrastructure Link\par
Overlay Network Security Model Link\par
28\par
Docker Certified Associate Linux Academy\par
We can encrypt communication that uses overlay networks within Docker Swarm with:\par
docker network create --opt encrypted --driver overlay NETWORK\par
Swarm-level communication between nodes is encrypted using MTLS (Mutually Authenticated Transport\par
Layer Security). This means that both participants in such communication authenticate with each other\par
(usually using certificates), and the communication is encrypted.\par
This also means that even if an attacker were able to view swarm-level network communications between\par
two nodes, they would likely be unable to extract any sensitive information from that data.\par
Securing the Docker Daemon HTTP Socket\par
Documentation:\par
Docker Daemon Security Link\par
1. Generate a certificate authority and server certificates for the Docker server. We must make sure\par
that we replace <server private IP> with the actual private IP of our server:\par
openssl genrsa -aes256 -out ca-key.pem 4096\par
openssl req -new -x509 -days 365 -key ca-key.pem -sha256 -out ca.pem -subj \\\par
"/C=US/ST=Texas/L=Keller/O=Linux Academy/OU=Content/CN=$HOSTNAME" \\\par
openssl genrsa -out server-key.pem 4096\par
openssl req -subj "/CN=$HOSTNAME" -sha256 -new -key server-key.pem -out server.csr \\\par
echo subjectAltName = DNS:$HOSTNAME,IP:<server private IP>,IP:127.0.0.1 >> extfile.cnf\par
echo extendedKeyUsage = serverAuth >> extfile.cnf\par
openssl x509 -req -days 365 -sha256 -in server.csr -CA ca.pem -CAkey ca-key.pem \\\par
-CAcreateserial -out server-cert.pem -extfile extfile.cnf\par
2. Generate client certificates:\par
openssl genrsa -out key.pem 4096\par
openssl req -subj '/CN=client' -new -key key.pem -out client.csr\par
echo extendedKeyUsage = clientAuth > extfile-client.cnf\par
openssl x509 -req -days 365 -sha256 -in client.csr -CA ca.pem -CAkey ca-key.pem \\\par
-CAcreateserial -out cert.pem -extfile extfile-client.cnf\par
3. Set appropriate permissions on the certificate files:\par
chmod -v 0400 ca-key.pem key.pem server-key.pem chmod -v 0444 ca.pem server-cert.pem cert.pem\par
4. Configure the Docker host to use tlsverify mode with the certificates created earlier:\par
sudo vi /etc/docker/daemon.json\par
29\par
Docker Certified Associate Linux Academy\par
\{\par
"tlsverify": true,\par
"tlscacert": "/home/cloud_user/ca.pem",\par
"tlscert": "/home/cloud_user/server-cert.pem",\par
"tlskey": "/home/cloud_user/server-key.pem"\par
\}\par
sudo vi /lib/systemd/system/docker.service\par
5. Look for the line that begins with ExecStart and change the -H so that it looks like this:\par
ExecStart=/usr/bin/dockerd -H=0.0.0.0:2376 --containerd=/run/containerd/containerd.sock\par
sudo systemctl daemon-reload\par
sudo systemctl restart docker\par
6. Copy the CA cert and client certificate files to the client machine:\par
scp ca.pem cert.pem key.pem cloud_user@:/home/cloud_user\par
7. On the client machine, configure the client to securely connect to the remote Docker daemon:\par
mkdir -pv ~/.docker\par
cp -v \{ca,cert,key\}.pem ~/.docker\par
export DOCKER_HOST=tcp://<docker server private \\\par
IP>:2376 DOCKER_TLS_VERIFY=1\par
8. Finally, we should test the connection:\par
docker version\par
Using Docker Enterprise Edition\par
Installing Docker EE\par
Documentation:\par
Docker EE for Ubuntu Link\par
To install Docker EE, we need a Docker Hub account and a Docker EE license. We can find a repository\par
URL which we can use to install Docker EE on Docker Hub.\par
1. We\rquote ll need a Docker Hub account. We can create one at {{\field{\*\fldinst{HYPERLINK https://hub.docker.com }}{\fldrslt{https://hub.docker.com\ul0\cf0}}}}\f1\fs22 .\par
30\par
Docker Certified Associate Linux Academy\par
2. Start a Docker EE free trial: {{\field{\*\fldinst{HYPERLINK https://hub.docker.com/editions/enterprise/docker-ee-trial }}{\fldrslt{https://hub.docker.com/editions/enterprise/docker-ee-trial\ul0\cf0}}}}\f1\fs22 .\par
3. Get a unique Docker EE URL from the trial:\par
4. Go to {{\field{\*\fldinst{HYPERLINK https://hub.docker.com/my-content }}{\fldrslt{https://hub.docker.com/my-content\ul0\cf0}}}}\f1\fs22 .\par
5. Click Setup.\par
6. Copy the URL.\par
7. Set up some temporary environment variables. Enter the unique Docker EE URL for the DOCKER_EE_URL\par
variable:\par
DOCKER_EE_URL=<your docker ee url>\par
DOCKER_EE_VERSION=18.09\par
8. Install required packages:\par
sudo apt-get install -y \\\par
apt-transport-https \\\par
ca-certificates \\\par
curl \\\par
software-properties-common\par
9. Add the GPG and apt -repository using the Docker EE URL:\par
curl -fsSL "$\{DOCKER_EE_URL\}/ubuntu/gpg" | sudo apt-key add -\par
sudo add-apt-repository \\\par
"deb [arch=$(dpkg --print-architecture)] $DOCKER_EE_URL/ubuntu \\\par
$(lsb_release -cs) \\\par
stable-$DOCKER_EE_VERSION"\par
10. Install Docker EE:\par
sudo apt-get update\par
sudo apt-get install -y docker-ee=5:18.09.4~3-0~ubuntu-bionic\par
11. Give cloud_user access to use Docker:\par
sudo usermod -a -G docker cloud_user\par
12. Log out of the server and log back in again, then test the Docker EE installation:\par
docker version\par
31\par
Docker Certified Associate Linux Academy\par
Setting up Universal Control Plane (UCP)\par
Documentation:\par
Install UCP for Production Link\par
UCP Overview Link\par
Universal Control Plane (UCP): An enterprise-level Docker cluster which provides a web UI that allows\par
us to manage the Docker swarm. It also includes a Kubernetes cluster, role-based access control (RBAC),\par
and other advanced features.\par
1. To install UCP, use the ucp image:\par
docker container run --rm -it --name ucp \\\par
-v /var/run/docker.sock:/var/run/docker.sock \\\par
docker/ucp:3.1.5 install \\\par
--host-address $PRIVATE_IP \\\par
--interactive\par
2. When prompted, create some admin credentials.\par
Note: We will also be prompted for Additional Aliases. Once this happens, hit enter to accept\par
the default value.\par
3. Once the installation is complete, access UCP in a web browser using the UCP manager\rquote s Public IP\par
address: {{\field{\*\fldinst{HYPERLINK https://<your }}{\fldrslt{https://<your\ul0\cf0}}}}\f1\fs22  UCP manager public IP>.\par
4. Log in to the UCP manager using the credentials we created earlier.\par
Note: We will be prompted to provide a license.\par
5. Open another tab and go to {{\field{\*\fldinst{HYPERLINK https://hub.docker.com/my-content }}{\fldrslt{https://hub.docker.com/my-content\ul0\cf0}}}}\f1\fs22 .\par
6. Click Setup.\par
7. Download the license using the license key link.\par
8. Go back to the UCP tab and click Upload License. Select the license file that we just downloaded\par
and upload it.\par
9. In a browser, on the UCP dashboard, click Shared Resources, Nodes, and then Add Node.\par
10. Make sure the node type is Linux and the node role is Worker. Then, copy the docker swarm join\par
command that appears on the page.\par
11. Run the docker swarm join obtained from the UCP manager on all worker nodes.\par
12. If we go to Shared Resources, and then Nodes on the UCP dashboard in a browser, we should see\par
both worker nodes appear in the list.\par
32\par
Docker Certified Associate Linux Academy\par
Security in UCP\par
Documentation:\par
Roles and Permission Levels Link\par
Access Control Model Link\par
LDAP Directory Integration Link\par
CLI-based Access Link\par
UCP implements its own role-based access control (RBAC) model with the following components:\par
\bullet  User: An authenticated person.\par
\bullet  Team: A group of users who share a set of permissions.\par
\bullet  Organization: A group of teams.\par
\bullet  Subject: A user, team, or organization.\par
\bullet  Collection: A set of objects in the swarm (containers, services, nodes etc.).\par
\bullet  Role: A specific permission that defines what an entity can do with regard to a collection of objects.\par
\bullet  Grant: Provides a specific permission (role) to a subject in regards to a collection.\par
Setting Up Docker Trusted Registry (DTR)\par
Documentation:\par
Install DTR Link\par
DTR Overview Link\par
Docker Trusted Registry (DTR): An enterprise-level private Docker registry with advanced features.\par
1. To install DTR, in the Universal Control Plane interface, go to admin.\par
2. Go to Admin Settings, and then Docker Trusted Registry.\par
3. Under UCP Node, select the worker node where we want to install DTR.\par
4. Check the checkbox labeled Disable TLS verification for UCP.\par
5. Copy the command provided on the page, then use a text editor to change the --ucp-url to specify\par
the Private IP of the UCP Manager server, not the public IP.\par
6. Run the modified command on the worker node at the desired location for installing DTR. The\par
command should look like this:\par
33\par
Docker Certified Associate Linux Academy\par
docker run -it --rm docker/dtr install \\\par
--ucp-node <DTR node hostname> \\\par
--ucp-username admin \\\par
--ucp-url {{\field{\*\fldinst{HYPERLINK https://<UCP }}{\fldrslt{https://<UCP\ul0\cf0}}}}\f1\fs22  Manager private IP> \\\par
--ucp-insecure-tls\par
7. When prompted for a password, enter the UCP admin password.\par
8. Once the installation is complete, access DTR in a browser at {{\field{\*\fldinst{HYPERLINK https://<DTR }}{\fldrslt{https://<DTR\ul0\cf0}}}}\f1\fs22  server public IP>.\par
9. Log in using the UCP admin credentials.\par
Sizing Requirements for Docker, UCP, and DTR\par
Documentation: Review Docker\rquote s site for an overview of the system requirements\par
UCP System Requirements Link\par
DTR System Requirements Link\par
Docker EE:\par
Remember that no specific sizing requirements exist because it depends on the containers we run.\par
Universal Control Plane:\par
\bullet  Minimum: 8 GB memory and 2 CPUs for manager nodes\par
\bullet  Recommended: 16 GB memory and 4 CPUs for manager nodes\par
\bullet  Minimum: 4 GB memory for worker nodes\par
Docker Trusted Registry:\par
\bullet  Minimum: 16 GB memory, 2 CPUs, 10 GB disk\par
\bullet  Recommended: 16 GB memory, 4 CPUs, 25-100 GB disk\par
Configuring Backups for UCP and DTR\par
Documentation:\par
Swarm of Docker Engines Administration Link\par
Backups and Disaster Recovery Link\par
DTR Backups and Recovery Link](https://docs.docker.com/datacenter/dtr/2.3/guides/admin/backups-anddisaster-recovery/)\par
34\par
Docker Certified Associate Linux Academy\par
Back Up the UCP\par
Remember that we must back up Docker Swarm separately when backing up UCP.\par
1. On the UCP server, retrieve the UCP instance ID:\par
docker container run --rm \\\par
--name ucp \\\par
-v /var/run/docker.sock:/var/run/docker.sock \\\par
docker/ucp:3.1.5 \\\par
id\par
2. Enter the UCP instance ID from the previous command for the --id flag, and create an encrypted\par
backup:\par
docker container run \\\par
--log-driver none --rm \\\par
--interactive \\\par
--name ucp \\\par
-v /var/run/docker.sock:/var/run/docker.sock \\\par
docker/ucp:3.1.5 backup \\\par
--passphrase "secretsecret" \\\par
--id <Your UCP instance ID> > /home/cloud_user/ucp-backup.tar\par
3. List the contents of the backup file:\par
gpg --decrypt /home/cloud_user/ucp-backup.tar | tar --list\par
Restore UCP from Backup\par
1. We must first uninstall UCP on the UCP manager server:\par
docker container run --rm -it \\\par
-v /var/run/docker.sock:/var/run/docker.sock \\\par
--name ucp \\\par
docker/ucp:3.1.5 uninstall-ucp --interactive\par
2. Restore UCP from the backup:\par
docker container run --rm -i --name ucp \\\par
-v /var/run/docker.sock:/var/run/docker.sock \\\par
docker/ucp:3.1.5 restore --passphrase "secretsecret" < /home/cloud_user/ucp-backup.tar\par
35\par
Docker Certified Associate Linux Academy\par
Back Up the DTR\par
1. On the DTR server, retrieve the DTR replica ID:\par
docker volume ls\par
Look for a volume name that begins with dtr-registry-. The string of letters and numbers at the end of\par
this volume make up the name of the DTR replica ID.\par
2. Back up the registry images:\par
sudo tar -zvcf dtr-backup-images.tar \\\par
$(dirname $(docker volume inspect --format '\{\{.Mountpoint\}\}' dtr-registry-<replica-id>))\par
3. Back up DTR metadata:\par
read -sp 'ucp password: ' UCP_PASSWORD; \\\par
docker run --log-driver none -i --rm \\\par
--env UCP_PASSWORD=$UCP_PASSWORD \\\par
docker/dtr:2.6.6 backup \\\par
--ucp-url {{\field{\*\fldinst{HYPERLINK https://<UCP }}{\fldrslt{https://<UCP\ul0\cf0}}}}\f1\fs22  Manager Private IP> \\\par
--ucp-insecure-tls \\\par
--ucp-username admin \\\par
--existing-replica-id <replica-id> > dtr-backup-metadata.tar\par
Restore DTR Backup\par
1. Stop the existing DTR replica with:\par
docker run -it --rm \\\par
docker/dtr:2.6.6 destroy \\\par
--ucp-insecure-tls \\\par
--ucp-username admin \\\par
--ucp-url {{\field{\*\fldinst{HYPERLINK https://<UCP }}{\fldrslt{https://<UCP\ul0\cf0}}}}\f1\fs22  Manager Private IP>\par
Restore images with:\par
sudo tar -xzf dtr-backup-images.tar -C /var/lib/docker/volumes\par
Restore DTR metadata with:\par
36\par
Docker Certified Associate Linux Academy\par
read -sp 'ucp password: ' UCP_PASSWORD; \\\par
docker run -i --rm \\\par
--env UCP_PASSWORD=$UCP_PASSWORD \\\par
docker/dtr:2.6.6 restore \\\par
--dtr-use-default-storage \\\par
--ucp-url {{\field{\*\fldinst{HYPERLINK https://<UCP }}{\fldrslt{https://<UCP\ul0\cf0}}}}\f1\fs22  Manager Private IP> \\\par
--ucp-insecure-tls \\\par
--ucp-username admin \\\par
--ucp-node <hostname> \\\par
--replica-id <replica-id> \\\par
--dtr-external-url <dtr-external-url> < dtr-backup-metadata.tar\par
DTR Security Features\par
Documentation:\par
Vulnerability Scanning in DTR Link\par
Overwritten Tag Prevention Link\par
Vulnerability Scanning: Docker Trusted Registry can scan our images for security vulnerabilities. We can\par
enable this option via the DTR UI.\par
By default, we must initiate scans manually, but we can choose to have images scanned automatically on\par
push in the repository settings.\par
We can also mark repositories as immutable, which prevents users from overwriting existing tags with a\par
new image.\par
Managing Certificates with UCP and DTR\par
Documentation:\par
TLS Certificates and Keys Configuration Link\par
TLS Certificate Setup Overview Link\par
CLI-based Access Link\par
Client Bundle: A package containing client certificates and setup scripts. We can download client bundles\par
from UCP and use them to authenticate with UCP as a Docker client.\par
We can provide our own certificates for UCP and DTR via their respective web UIs.\par
37\f0\par
}
 